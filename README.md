# text-toxicity-detection
The TensorFlow.js toxicity model is used, which classifies text according to whether it exhibits offensive attributes or not. The toxicity model detects whether text contains toxic content such as threatening language, insults, obscenities, identity-based hate, or any explicit language.
